{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MDP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBMshJ4TY2fMWHWBd6wM/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksevenli/Pytorch-Reinforcement-Learning/blob/master/MDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qXoDOlg8uzV",
        "colab_type": "text"
      },
      "source": [
        "S0 study S1 Sleep S2 play games\n",
        "\n",
        "a0 work  a1 slack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfPUv5VSrUMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FciEYNdT8HgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = torch.tensor([[[0.8, 0.1, 0.1],\n",
        " [0.1, 0.6, 0.3]],\n",
        "[[0.7, 0.2, 0.1],\n",
        "[0.1, 0.8, 0.1]],\n",
        "[[0.6, 0.2, 0.2],\n",
        "[0.1, 0.4, 0.5]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkRTixqK8lqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the reward function and the discount factor:\n",
        "R = torch.tensor([1., 0, -1.])\n",
        "# Discount factor\n",
        "gamma = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2btyKjj9L3_",
        "colab_type": "text"
      },
      "source": [
        "The optimal policy in this case is selecting action a0 in all circumstances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-kOyypp9LQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ZgYJZj9YnR",
        "colab_type": "text"
      },
      "source": [
        "We calculate the value, V, of the optimal policy using the matrix inversion method in the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BzNCq3S9U7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_value_matrix_inversion(gamma, trans_matrix, rewards):\n",
        "    inv = torch.inverse(torch.eye(rewards.shape[0]) - gamma * trans_matrix)\n",
        "    V = torch.mm(inv, rewards.reshape(-1, 1))\n",
        "    return V"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtqexPfA-KrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8dff41c3-a3bd-46df-f688-668725dafd39"
      },
      "source": [
        "# Feed all variables we have to the function, including the transition probabilities associated with action a0\n",
        "trans_matrix = T[:, action]\n",
        "#print(trans_matrix)\n",
        "V = cal_value_matrix_inversion(gamma, trans_matrix, R)\n",
        "print(\"The value function under the optimal policy is: \\n{}\".format(V))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The value function under the optimal policy is: \n",
            "tensor([[ 1.6787],\n",
            "        [ 0.6260],\n",
            "        [-0.4820]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hDZuxMv-5at",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}